# ğŸ¤– Gestify â€“ Hand Gesture Recognition System

**Gestify** is a smart, real-time hand gesture recognition system that uses advanced computer vision, machine learning, and bio-inspired optimization techniques to accurately identify static hand gestures. It is especially useful for applications such as sign language recognition, gesture-based control systems, and assistive communication tools.

---

## ğŸ“Œ Features
- ğŸ“· Real-time hand landmark detection using MediaPipe
- ğŸ§  Gesture classification using Adaptive Extreme Learning Machine (AELM)
- ğŸŒ€ Feature selection powered by Manta-Ray Foraging Optimization (MRFO)
- ğŸ§® Multifaceted Feature Extraction (MFE) for accuracy
- ğŸ¯ Lightweight model with ~92% accuracy and ~25 FPS performance
- ğŸ›ï¸ Integrated UI using Streamlit and Streamlit WebRTC for ease of use

---

## ğŸ§° Technologies Used
- **Programming Language:** Python
- **Libraries & Tools:** OpenCV, MediaPipe, Streamlit, NumPy, Scikit-learn, TensorFlow/Keras
- **Frameworks:** Streamlit, streamlit-webrtc
- **Optimization:** MRFO, AELM
- **Dataset:** ASL-finger, Sebastian Marcel

---

## ğŸ§  How It Works
1. **Live video input** is captured from a webcam.
2. **MediaPipe** detects and extracts 21 hand landmarks.
3. **MFE** processes these points into a structured feature vector.
4. **MRFO** optimizes the feature set and hyperparameters.
5. **AELM classifier** predicts the gesture.
6. **Output** is displayed on the live video stream with instant feedback.

---

## ğŸ“¸ Screenshots
![image](https://github.com/user-attachments/assets/7df92d13-ef64-4378-b0ad-e6871e2eb10e)

![image](https://github.com/user-attachments/assets/437a6023-0bd7-475b-b6db-cda3f87eb3b2)

![image](https://github.com/user-attachments/assets/ff13a040-9c48-46c7-929f-06d76be53d00)

![Screenshot 2025-04-15 153844](https://github.com/user-attachments/assets/906eeba1-eb77-4531-9a69-87feb8cb9858)

![Screenshot 2025-04-15 153955](https://github.com/user-attachments/assets/a61d289e-7e39-46f9-a61a-cbae9fb8fe7f)

![Screenshot 2025-04-15 153923](https://github.com/user-attachments/assets/5d464ca8-72b2-47ae-8f21-13b7595486bd)


---

## ğŸ”¬ Performance Summary
| Metric              | Result        |
|---------------------|---------------|
| Validation Accuracy | ~92%          |
| Test Accuracy       | ~89.5%        |

---

## ğŸš€ Future Enhancements
- Dynamic gesture recognition using LSTM or 3D CNNs
- Voice synthesis for gesture-to-speech translation
- Cloud-based training and database logging
- Multi-hand and multi-user support
- Mobile app deployment via TensorFlow Lite
- Regional sign language recognition



